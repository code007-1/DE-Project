{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Batch Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the module\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import finnhub\n",
    "import wikipedia\n",
    "from pymongo import MongoClient\n",
    "import keys\n",
    "import datetime\n",
    "\n",
    "# setup finnhub and mongodb client\n",
    "finnhub_client = finnhub.Client(api_key=keys.finnhub_api_key)\n",
    "client = MongoClient(f\"mongodb+srv://{keys.mongodb_username}:{keys.mongodb_password}@clusternex.c1ok7xn.mongodb.net/Stocks_Data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Load Historical Data of All Stocks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Loading AAPL.csv data...\n",
      "Done Loading ABNB.csv data...\n",
      "Done Loading ADBE.csv data...\n",
      "Done Loading AEP.csv data...\n",
      "Done Loading AMD.csv data...\n",
      "Done Loading AMZN.csv data...\n",
      "Done Loading ATVI.csv data...\n",
      "Done Loading COKE.csv data...\n",
      "Done Loading CSCO.csv data...\n",
      "Done Loading EA.csv data...\n",
      "Done Loading EBAY.csv data...\n",
      "Done Loading F.csv data...\n",
      "Done Loading GOOG.csv data...\n",
      "Done Loading HON.csv data...\n",
      "Done Loading INTC.csv data...\n",
      "Done Loading META.csv data...\n",
      "Done Loading MSFT.csv data...\n",
      "Done Loading NFLX.csv data...\n",
      "Done Loading NVDA.csv data...\n",
      "Done Loading PYPL.csv data...\n",
      "Done Loading QCOM.csv data...\n",
      "Done Loading SBUX.csv data...\n",
      "Done Loading TEAM.csv data...\n",
      "Done Loading TSLA.csv data...\n",
      "Done Loading TTWO.csv data...\n",
      "Done Loading TXN.csv data...\n",
      "Done Loading WBD.csv data...\n",
      "Done Loading XPEV.csv data...\n"
     ]
    }
   ],
   "source": [
    "# read all csv in given folder and load data to databse\n",
    "for dr in os.listdir(\"./historical-data/\"):\n",
    "    # read data\n",
    "    data = pd.read_csv(\"./historical-data/\"+dr)\n",
    "\n",
    "    # apply some simpe transformations\n",
    "    data.columns = [\"date\", \"close\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "    data[\"close\"] = data[\"close\"].apply(lambda x: float(str(x).removeprefix(\"$\")))\n",
    "    data[\"open\"] = data[\"open\"].apply(lambda x: float(str(x).removeprefix(\"$\")))\n",
    "    data[\"high\"] = data[\"high\"].apply(lambda x: float(str(x).removeprefix(\"$\")))\n",
    "    data[\"low\"] = data[\"low\"].apply(lambda x: float(str(x).removeprefix(\"$\")))\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data = data.sort_values(by='date')\n",
    "\n",
    "    # store data in mongodb having collection name same as file name\n",
    "    collection = client[\"Stocks_Data\"][dr.removesuffix(\".csv\")]\n",
    "    collection.insert_many(data.to_dict(\"records\"))\n",
    "    \n",
    "    print(\"Done Loading \" + dr + \" data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shares = [\"AAPL\", \"GOOG\", \"MSFT\", \"CSCO\", \"META\", \"AMZN\", \"EBAY\", \"TSLA\", \"ADBE\", \"NFLX\", \"SBUX\", \"AMD\", \"NVDA\", \"QCOM\", \"INTC\", \"EA\", \"ATVI\", \"TTWO\", \"PYPL\", \"COKE\", \"TXN\", \"XPEV\", \"F\", \"ABNB\", \"AEP\", \"TEAM\", \"HON\", \"WBD\"]\n",
    "\n",
    "def DateTimeToTimeStamp(dateTime):\n",
    "    \"\"\"Converts Date to Time Stamp\"\"\"\n",
    "\n",
    "    return datetime.datetime.strptime(str(dateTime), \"%Y-%m-%d %H:%M:%S\").timestamp().__int__()\n",
    "\n",
    "\n",
    "def TimeStampToDateTime(timeStamp):\n",
    "    \"\"\"Convert Time Stamp to DateTime\"\"\"\n",
    "\n",
    "    return datetime.datetime.fromtimestamp(timeStamp)\n",
    "\n",
    "\n",
    "def TimeStampToDate(timeStamp):\n",
    "    \"\"\"Convert Time Stamp to Date\"\"\"\n",
    "\n",
    "    return datetime.datetime.fromtimestamp(timeStamp).date()\n",
    "\n",
    "\n",
    "def Extract_Data(time=None):\n",
    "    \"\"\"Extract Current Price Information of Stocks\"\"\"\n",
    "\n",
    "    # Setup Finnhub client\n",
    "    client = finnhub.Client(api_key=keys.finnhub_api_key)\n",
    "\n",
    "    # Create a dataframe to store data\n",
    "    data = pd.DataFrame(columns=[\"c\", \"h\", \"l\", \"o\", \"s\", \"t\", \"v\", \"symbol\"])\n",
    "\n",
    "    # current time\n",
    "    if time == None:\n",
    "        time = DateTimeToTimeStamp(datetime.datetime.now().isoformat(\" \", \"seconds\"))\n",
    "\n",
    "    # Extract data of each share\n",
    "    for share in shares:\n",
    "        dataDictionary = client.stock_candles(share, \"D\", time, time)\n",
    "        dataDictionary[\"symbol\"] = share\n",
    "        data = pd.concat([data, pd.DataFrame(dataDictionary)], ignore_index=True)\n",
    "\n",
    "    # change column names\n",
    "    data.columns = [\n",
    "        \"close\",\n",
    "        \"high\",\n",
    "        \"low\",\n",
    "        \"open\",\n",
    "        \"status\",\n",
    "        \"date\",\n",
    "        \"volume\",\n",
    "        \"symbol\",\n",
    "    ]\n",
    "\n",
    "    return data\n",
    "\n",
    "def Transform_Data(data):\n",
    "    \"\"\"Apply some simple Transformations\"\"\"\n",
    "    \n",
    "    data[\"date\"] = data[\"date\"].apply(TimeStampToDateTime)\n",
    "    data = data.astype({\"volume\": int})\n",
    "    data = data.drop(\"status\", axis=1)\n",
    "\n",
    "    data = data.reindex(\n",
    "        columns=[\"date\", \"close\", \"volume\", \"open\", \"high\", \"low\", \"symbol\"]\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "def Load_Day_End_Data(data):\n",
    "    \"\"\"Loads Data to Mongodb Database\"\"\"\n",
    "\n",
    "    # Setup Mongodb Connection\n",
    "    url = f\"mongodb+srv://{keys.mongodb_username}:{keys.mongodb_password}@clusternex.c1ok7xn.mongodb.net/Stocks_Data\"\n",
    "    client = MongoClient(url)\n",
    "\n",
    "    # Select Database\n",
    "    dataBaseObject = client[\"Stocks_Data\"][\"Real_Time_Data\"]\n",
    "\n",
    "    symbols = data[\"symbol\"]\n",
    "    data = data.drop(\"symbol\", axis=1)\n",
    "    data = data.to_dict(\"records\")\n",
    "\n",
    "    # insert day end data in database\n",
    "    for s, d in zip(symbols, data):\n",
    "        # Select collection\n",
    "        dataBaseObject = client[\"Stocks_Data\"][s]\n",
    "        dataBaseObject.insert_one(d)\n",
    "\n",
    "    client.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2 Load Any Previous Data that is not available upto yesterday's date from finnhub api**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collection = client[\"Stocks_Data\"][\"AAPL\"]\n",
    "data = collection.find({}).sort(\"date\", -1).limit(1)\n",
    "\n",
    "date = data[0][\"date\"]\n",
    "date = date + datetime.timedelta(days=1, hours=18)\n",
    "\n",
    "# if date is not current date and not saturday and sunday then insert date's data\n",
    "while(date.date() < datetime.datetime.now().date() and date.date().weekday() < 5):\n",
    "    data = Extract_Data(DateTimeToTimeStamp(date.isoformat(\" \", \"seconds\")))\n",
    "    data = Transform_Data(data)\n",
    "    Load_Day_End_Data(data)\n",
    "    date = date + datetime.timedelta(days=1, hours=18)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1 Fetch Company Stock Data from Finnhab API like Company Profile Data, Basic Financials Metrices, Annual Fianancials Data, Sell/Buy Recommendation etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []\n",
    "\n",
    "# fetch data from finnhub api\n",
    "for s in shares:\n",
    "\n",
    "    # company profile data \n",
    "    data = finnhub_client.company_profile2(symbol=s)\n",
    "    profile_type = [\"country\", \"currency\", \"exchange\", \"finnhubIndustry\", \"ipo\", \"logo\", \"name\", \"ticker\", \"weburl\"]\n",
    "    company_profile = {}\n",
    "    for x in profile_type:\n",
    "        try:\n",
    "            company_profile[x] = data[x]\n",
    "        finally:\n",
    "            continue\n",
    "    \n",
    "    # remove ticker as it would be added later manually at top level of data    \n",
    "    company_profile.pop(\"ticker\")\n",
    "    \n",
    "    # company short descrtiption\n",
    "    company_profile[\"description\"] = wikipedia.summary(company_profile[\"name\"], sentences = 5)\n",
    "    \n",
    "    # basic financials metrices\n",
    "    data = finnhub_client.company_basic_financials(s, 'all')\n",
    "    metric_types = [\"13WeekPriceReturnDaily\", \"26WeekPriceReturnDaily\", \"52WeekHigh\", \"52WeekLow\", \"currentRatioAnnual\", \"quickRatioAnnual\", \"epsAnnual\", \"roiAnnual\", \"bookValuePerShareAnnual\", \"cashFlowPerShareAnnual\", \"dividendPerShareAnnual\", \"marketCapitalization\", \"netProfitMarginAnnual\"]\n",
    "    metric = {}\n",
    "    for x in metric_types:\n",
    "        try:\n",
    "            metric[x] = data[\"metric\"][x]\n",
    "        finally:\n",
    "            continue\n",
    "\n",
    "    # annual financial data\n",
    "    series_types = {\"eps\", \"longtermDebtTotalEquity\", \"totalDebtToEquity\", \"cashRatio\"}\n",
    "    series = {}\n",
    "    for x in series_types:\n",
    "        try:\n",
    "            series[x] = data[\"series\"][\"annual\"][x]\n",
    "        finally:\n",
    "            continue\n",
    "\n",
    "    # recommendations for the company stock\n",
    "    data = finnhub_client.recommendation_trends(s)[0]\n",
    "    data.pop(\"symbol\")\n",
    "\n",
    "    # add data to list\n",
    "    final_data.append({\"symbol\": s, \"basics\": company_profile, \"metric\":metric, \"series\":series, \"recommendations\":data})\n",
    "\n",
    "    # 2 seconds sleep so that, we won't exceed api call limit\n",
    "    time.sleep(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Load Data to Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x255f90cb0a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store data in mongodb\n",
    "client = client[\"Stocks_Data\"][\"Stocks_Information\"]\n",
    "client.insert_many(final_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
